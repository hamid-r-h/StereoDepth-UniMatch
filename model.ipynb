{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe68d7f9-a21e-4021-8d09-6858e96a8bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /home/hamid/.local/lib/python3.8/site-packages (4.46.2)\n",
      "Requirement already satisfied: datasets in /home/hamid/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /home/hamid/.local/lib/python3.8/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/hamid/.local/lib/python3.8/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hamid/.local/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hamid/.local/lib/python3.8/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hamid/.local/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hamid/.local/lib/python3.8/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/hamid/.local/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/hamid/.local/lib/python3.8/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/hamid/.local/lib/python3.8/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/hamid/.local/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/hamid/.local/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: xxhash in /home/hamid/.local/lib/python3.8/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/hamid/.local/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /home/hamid/.local/lib/python3.8/site-packages (from datasets) (3.10.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/hamid/.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/hamid/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/hamid/.local/lib/python3.8/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/hamid/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/hamid/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/hamid/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/hamid/.local/lib/python3.8/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/hamid/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hamid/.local/lib/python3.8/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hamid/.local/lib/python3.8/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.14.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/hamid/.local/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Installing collected packages: pytz, requests, python-dateutil, fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nbconvert 7.16.4 requires markupsafe>=2.0, but you have markupsafe 1.1.0 which is incompatible.\n",
      "notebook 7.2.2 requires jupyterlab<4.3,>=4.2.0, but you have jupyterlab 4.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2024.9.0 python-dateutil-2.9.0.post0 pytz-2024.2 requests-2.32.3\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement requirements.txt (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0mHINT: You are attempting to install a package literally named \"requirements.txt\" (which cannot exist). Consider using the '-r' flag to install the packages listed in requirements.txt\n",
      "\u001b[31mERROR: No matching distribution found for requirements.txt\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gradio in /home/hamid/.local/lib/python3.8/site-packages (4.44.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (4.5.2)\n",
      "Requirement already satisfied: fastapi<1.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.115.5)\n",
      "Requirement already satisfied: ffmpy in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.26.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (3.1.4)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (3.7.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (1.24.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (3.10.11)\n",
      "Requirement already satisfied: packaging in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (2.0.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (2.9.2)\n",
      "Requirement already satisfied: pydub in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.0.17)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/lib/python3/dist-packages (from gradio) (5.3.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.7.4)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (4.12.2)\n",
      "Collecting urllib3~=2.0 (from gradio)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio) (0.32.0)\n",
      "Requirement already satisfied: fsspec in /home/hamid/.local/lib/python3.8/site-packages (from gradio-client==1.3.0->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/hamid/.local/lib/python3.8/site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5.0,>=3.0->gradio) (2.8)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/hamid/.local/lib/python3.8/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/hamid/.local/lib/python3.8/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /home/hamid/.local/lib/python3.8/site-packages (from fastapi<1.0->gradio) (0.41.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx>=0.24.1->gradio) (2019.11.28)\n",
      "Requirement already satisfied: httpcore==1.* in /home/hamid/.local/lib/python3.8/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/hamid/.local/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/hamid/.local/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.22.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/hamid/.local/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->gradio) (4.67.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/hamid/.local/lib/python3.8/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.20.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib~=3.0->gradio) (2.7.3)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib~=3.0->gradio)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/hamid/.local/lib/python3.8/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/hamid/.local/lib/python3.8/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/hamid/.local/lib/python3.8/site-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/hamid/.local/lib/python3.8/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/hamid/.local/lib/python3.8/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/hamid/.local/lib/python3.8/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/hamid/.local/lib/python3.8/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/hamid/.local/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Installing collected packages: pytz, urllib3, python-dateutil, markupsafe, click\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.22.0 which is incompatible.\n",
      "notebook 7.2.2 requires jupyterlab<4.3,>=4.2.0, but you have jupyterlab 4.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed click-8.1.7 markupsafe-2.1.5 python-dateutil-2.9.0.post0 pytz-2024.2 urllib3-2.2.3\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: opencv-python in /home/hamid/.local/lib/python3.8/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/hamid/.local/lib/python3.8/site-packages (from opencv-python) (1.24.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tifffile in /home/hamid/.local/lib/python3.8/site-packages (2023.7.10)\n",
      "Requirement already satisfied: matplotlib in /home/hamid/.local/lib/python3.8/site-packages (3.7.5)\n",
      "Requirement already satisfied: numpy in /home/hamid/.local/lib/python3.8/site-packages (from tifffile) (1.24.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib) (2.7.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/hamid/.local/lib/python3.8/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/hamid/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: rasterio in /home/hamid/.local/lib/python3.8/site-packages (1.3.11)\n",
      "Requirement already satisfied: affine in /home/hamid/.local/lib/python3.8/site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /home/hamid/.local/lib/python3.8/site-packages (from rasterio) (24.2.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from rasterio) (2019.11.28)\n",
      "Requirement already satisfied: click>=4.0 in /usr/lib/python3/dist-packages (from rasterio) (7.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /home/hamid/.local/lib/python3.8/site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy in /home/hamid/.local/lib/python3.8/site-packages (from rasterio) (1.24.4)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /home/hamid/.local/lib/python3.8/site-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /home/hamid/.local/lib/python3.8/site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /home/hamid/.local/lib/python3.8/site-packages (from rasterio) (75.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/hamid/.local/lib/python3.8/site-packages (from rasterio) (8.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /home/hamid/.local/lib/python3.8/site-packages (from snuggs>=1.4.1->rasterio) (3.1.4)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/hamid/.local/lib/python3.8/site-packages (from importlib-metadata->rasterio) (3.20.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /home/hamid/.local/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /home/hamid/.local/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/hamid/.local/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/hamid/.local/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/hamid/.local/lib/python3.8/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hamid/.local/lib/python3.8/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hamid/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.77)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hamid/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Installing collected packages: MarkupSafe\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 4.44.1 requires urllib3~=2.0, but you have urllib3 1.25.8 which is incompatible.\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.22.0 which is incompatible.\n",
      "notebook 7.2.2 requires jupyterlab<4.3,>=4.2.0, but you have jupyterlab 4.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-2.1.5\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: onnxscript in /home/hamid/.local/lib/python3.8/site-packages (0.1.0.dev20241112)\n",
      "Requirement already satisfied: numpy in /home/hamid/.local/lib/python3.8/site-packages (from onnxscript) (1.24.4)\n",
      "Requirement already satisfied: onnx>=1.16 in /home/hamid/.local/lib/python3.8/site-packages (from onnxscript) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions in /home/hamid/.local/lib/python3.8/site-packages (from onnxscript) (4.12.2)\n",
      "Requirement already satisfied: ml-dtypes in /home/hamid/.local/lib/python3.8/site-packages (from onnxscript) (0.2.0)\n",
      "Requirement already satisfied: packaging in /home/hamid/.local/lib/python3.8/site-packages (from onnxscript) (24.2)\n",
      "Collecting protobuf>=3.20.2 (from onnx>=1.16->onnxscript)\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-5.28.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets\n",
    "!pip install requirements.txt\n",
    "!pip install gradio\n",
    "!pip install opencv-python\n",
    "import cv2\n",
    "!pip install tifffile matplotlib \n",
    "!pip install rasterio\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install torch --upgrade\n",
    "!pip install onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f00289-f8dc-4811-93ed-6d34673995db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 63\u001b[0m\n\u001b[1;32m     54\u001b[0m img_points_right \u001b[38;5;241m=\u001b[39m [pts_right]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Stereo calibration to find the rotation and translation between the two cameras\u001b[39;00m\n\u001b[1;32m     57\u001b[0m ret, K1, dist1, K2, dist2, R, T, E, F \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mstereoCalibrate(\n\u001b[1;32m     58\u001b[0m     obj_points,\n\u001b[1;32m     59\u001b[0m     img_points_left,\n\u001b[1;32m     60\u001b[0m     img_points_right,\n\u001b[1;32m     61\u001b[0m     K1, dist1, K2, dist2,\n\u001b[1;32m     62\u001b[0m     imageSize\u001b[38;5;241m=\u001b[39m(img_left\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img_left\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m---> 63\u001b[0m     R\u001b[38;5;241m=\u001b[39m\u001b[43mR\u001b[49m, T\u001b[38;5;241m=\u001b[39mT, E\u001b[38;5;241m=\u001b[39mE, F\u001b[38;5;241m=\u001b[39mF,\n\u001b[1;32m     64\u001b[0m     criteria\u001b[38;5;241m=\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m+\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_MAX_ITER, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m1e-6\u001b[39m),\n\u001b[1;32m     65\u001b[0m     flags\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mCALIB_FIX_INTRINSIC\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Print the results for debugging\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRotation matrix (R):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, R)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'R' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Intrinsic parameters for the Sony FCB-7520 camera\n",
    "K1 = np.array([[350, 0, 320],\n",
    "               [0, 350, 240],\n",
    "               [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "K2 = np.array([[350, 0, 320],\n",
    "               [0, 350, 240],\n",
    "               [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "dist1 = np.array([0.01, -0.02, 0.0, 0.0, 0.0], dtype=np.float64)\n",
    "dist2 = np.array([0.01, -0.02, 0.0, 0.0, 0.0], dtype=np.float64)\n",
    "\n",
    "# Load stereo images (left and right images)\n",
    "img_left = cv2.imread('examples/ImageLeft/0100_L.png', 0)\n",
    "img_right = cv2.imread('examples/ImageRight/0100_R.png', 0)\n",
    "\n",
    "if img_left is None or img_right is None:\n",
    "    print(\"Error: One or both of the images were not loaded correctly.\")\n",
    "else:\n",
    "    # Initialize ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Detect ORB keypoints and compute descriptors for both images\n",
    "    kp1, des1 = orb.detectAndCompute(img_left, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img_right, None)\n",
    "\n",
    "    # Use BFMatcher to match the descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "\n",
    "    # Sort the matches based on their distance\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Draw matches\n",
    "    img_matches = cv2.drawMatches(img_left, kp1, img_right, kp2, matches[:50], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.imshow('Matches', img_matches)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Extract the matched keypoints\n",
    "    pts_left = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    pts_right = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Generate synthetic object points (if actual 3D points are not available)\n",
    "    objp = np.zeros((len(pts_left), 3), np.float32)\n",
    "    objp[:, 0] = np.arange(len(pts_left))\n",
    "\n",
    "    # Arrays to store object points and image points\n",
    "    obj_points = [objp]\n",
    "    img_points_left = [pts_left]\n",
    "    img_points_right = [pts_right]\n",
    "\n",
    "    # Stereo calibration to find the rotation and translation between the two cameras\n",
    "    ret, K1, dist1, K2, dist2, R, T, E, F = cv2.stereoCalibrate(\n",
    "        obj_points,\n",
    "        img_points_left,\n",
    "        img_points_right,\n",
    "        K1, dist1, K2, dist2,\n",
    "        imageSize=(img_left.shape[1], img_left.shape[0]),\n",
    "        R=R, T=T, E=E, F=F,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-6),\n",
    "        flags=cv2.CALIB_FIX_INTRINSIC\n",
    "    )\n",
    "\n",
    "    # Print the results for debugging\n",
    "    print(\"Rotation matrix (R):\\n\", R)\n",
    "    print(\"Translation vector (T):\\n\", T)\n",
    "    print(\"Essential matrix (E):\\n\", E)\n",
    "    print(\"Fundamental matrix (F):\\n\", F)\n",
    "    print(\"Calibration return value:\", ret)\n",
    "\n",
    "    # Calculate the baseline as the norm of the translation vector T\n",
    "    if np.any(T):\n",
    "        baseline = np.linalg.norm(T)\n",
    "        print(f\"Baseline: {baseline} meters\")\n",
    "    else:\n",
    "        print(\"Translation vector (T) is zero or invalid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "725d9373-0e11-44c8-81dc-aa4032cdac49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'click.shell_completion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inference\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gradio/__init__.py:115\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwasm_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IS_WASM\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m IS_WASM:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deploy\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mipython_ext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_ipython_extension\n\u001b[1;32m    118\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m get_package_version()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gradio/cli/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cli, deploy\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommands\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_component\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcli\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeploy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_component\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/gradio/cli/cli.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyper\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deploy_discord  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrich\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconsole\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Console\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/typer/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_file \u001b[38;5;28;01mas\u001b[39;00m open_file\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors \u001b[38;5;28;01mas\u001b[39;00m colors\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Typer \u001b[38;5;28;01mas\u001b[39;00m Typer\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run \u001b[38;5;28;01mas\u001b[39;00m run\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackParam \u001b[38;5;28;01mas\u001b[39;00m CallbackParam\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/typer/main.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_args, get_origin, is_union\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompletion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_completion_inspect_parameters\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarkupMode, TyperArgument, TyperCommand, TyperGroup, TyperOption\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     AnyType,\n\u001b[1;32m     21\u001b[0m     ArgumentInfo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     TyperInfo,\n\u001b[1;32m     37\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/typer/completion.py:7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, MutableMapping, Tuple\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_completion_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m completion_init\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_completion_shared\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Shells, get_completion_script, install\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParamMeta\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/typer/_completion_classes.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclick\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshell_completion\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_completion_shared\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     COMPLETION_SCRIPT_BASH,\n\u001b[1;32m     12\u001b[0m     COMPLETION_SCRIPT_FISH,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     Shells,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'click.shell_completion'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from app import inference\n",
    "from app import load_model\n",
    "from app import convert_to_onnx\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "def get_disp(image1, image2, result_pth):\n",
    "    model = load_model()\n",
    "    result = inference(image1, image2, model, task='stereo')\n",
    "    #result.save(result_pth)\n",
    "    result = np.array(result)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(result)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    return result\n",
    "def get_depth(focal_length,baseline,cx1,cx2,disparity):\n",
    "    depth = (focal_length * baseline) / (np.abs(-disparity + (cx2 - cx1)))\n",
    "    return depth\n",
    "\n",
    "\n",
    "img1 = Image.open('examples/ImageLeft/0100_L.png')\n",
    "img2 = Image.open('examples/ImageRight/0100_R.png')\n",
    "# Convert the PIL image to a NumPy array\n",
    "img_np = np.array(img1)\n",
    "image_height, image_width = img_np.shape[:2]\n",
    "\n",
    "cx = image_width / 2\n",
    "cy = image_height / 2\n",
    "img1 = np.array(img1)\n",
    "img2 = np.array(img2)\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Find the keypoints and descriptors with ORB\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "img3 = cv2.drawKeypoints(img1, kp1, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img3), plt.show()\n",
    "\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params = dict(algorithm = FLANN_INDEX_LSH,\n",
    "                    table_number = 6,  # 12\n",
    "                    key_size = 12,     # 20\n",
    "                    multi_probe_level = 1)  #2\n",
    "\n",
    "search_params = dict(checks=50)  # or pass an empty dictionary\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Match descriptors using KNN\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "# Sort them in the order of their distance\n",
    "\n",
    "# Store only good matches using the ratio test\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7  * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "fx,fy=35,35\n",
    "# Assuming you have the camera intrinsic parameters K\n",
    "K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "if len(pts1) >= 5 and len(pts2) >= 5:\n",
    "    # Compute essential matrix\n",
    "    E, mask = cv2.findEssentialMat(pts1, pts2, K)\n",
    "    if E is not None:\n",
    "        print(\"Essential Matrix:\\n\", E)\n",
    "\n",
    "        # Recover pose (rotation and translation)\n",
    "        _, R, t, mask_pose = cv2.recoverPose(E, pts1, pts2, K)\n",
    "\n",
    "        # Baseline length is the magnitude of the translation vector t (initially in relative scale)\n",
    "        baseline = np.linalg.norm(t)\n",
    "        print(\"Initial Baseline (Relative): \", baseline)\n",
    "\n",
    "        # Here you would scale the baseline based on a known distance in the scene.\n",
    "        # Assuming D is the known distance in meters between two triangulated points:\n",
    "        D = 5.0  # For example, 5 meters\n",
    "\n",
    "        # Perform triangulation to estimate the 3D positions of points in the scene\n",
    "        pts1_normalized = cv2.undistortPoints(pts1, K, None)\n",
    "        pts2_normalized = cv2.undistortPoints(pts2, K, None)\n",
    "        \n",
    "        points_4d_hom = cv2.triangulatePoints(np.dot(K, np.hstack((np.eye(3), np.zeros((3, 1))))),\n",
    "                                              np.dot(K, np.hstack((R, t))),\n",
    "                                              pts1_normalized, pts2_normalized)\n",
    "\n",
    "        points_4d = points_4d_hom[:3] / points_4d_hom[3]\n",
    "\n",
    "        # Select two points and calculate the distance between them in the 3D space\n",
    "        point1 = points_4d[:, 0]\n",
    "        point2 = points_4d[:, 1]\n",
    "        distance_3d = np.linalg.norm(point1 - point2)\n",
    "\n",
    "        # Scale the baseline based on the known distance\n",
    "        scale_factor = D / distance_3d\n",
    "        scaled_baseline = baseline * scale_factor\n",
    "\n",
    "        print(\"Scaled Baseline: \", scaled_baseline)\n",
    "    else:\n",
    "        print(\"Essential matrix calculation failed.\")\n",
    "else:\n",
    "    print(\"Not enough points to compute the essential matrix.\")\n",
    "\n",
    "# Termination criteria for corner refinement\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points (0,0,0), (1,0,0), ..., (7,5,0)\n",
    "objp = np.zeros((6*9, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints_left = []  # 2d points in image plane of left camera\n",
    "imgpoints_right = []  # 2d points in image plane of right camera\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to detect and compute features using ORB\n",
    "def detect_and_compute_features(image):\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints, descriptors = orb.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "# Function to match features using FLANN-based matcher\n",
    "def match_features(descriptors1, descriptors2):\n",
    "    # FLANN parameters\n",
    "    index_params = dict(algorithm=6, table_number=6, key_size=12, multi_probe_level=1)\n",
    "    search_params = dict(checks=50)  # or pass empty dictionary\n",
    "    \n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    \n",
    "    # Ratio test\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    return good_matches\n",
    "\n",
    "\n",
    "images_left = cv2.imread('examples/ImageLeft/0100_L.png')\n",
    "images_right = cv2.imread('examples/ImageRight/0100_R.png')\n",
    "    \n",
    "# Convert images to grayscale\n",
    "gray_left = cv2.cvtColor(images_left, cv2.COLOR_BGR2GRAY)\n",
    "gray_right = cv2.cvtColor(images_right, cv2.COLOR_BGR2GRAY)\n",
    "#images_left = np.array(images_left)\n",
    "#images_right = np.array(images_right)\n",
    "#images_left = cv2.medianBlur(images_left, 3)\n",
    "#images_right = cv2.medianBlur(images_right, 3)\n",
    "\n",
    "\n",
    "# Detect and compute features\n",
    "keypointsL, descriptorsL = detect_and_compute_features(gray_left)\n",
    "keypointsR, descriptorsR = detect_and_compute_features(gray_right)\n",
    "img3 = cv2.drawKeypoints(images_left, keypointsL, None, color=(0,255,0), flags=0)\n",
    "plt.imshow(img3), plt.show()\n",
    "\n",
    "# Match features\n",
    "matches = match_features(descriptorsL, descriptorsR)\n",
    "\n",
    "# Extract matched points\n",
    "matched_points_left = np.float32([keypointsL[m.queryIdx].pt for m in matches])\n",
    "matched_points_right = np.float32([keypointsR[m.trainIdx].pt for m in matches])\n",
    "    # Assume camera intrinsic matrix K (for both cameras, same intrinsic parameters)\n",
    "fx,fy=35,35\n",
    "K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0, 0, 1]])\n",
    "    \n",
    "    # Compute the essential matrix\n",
    "E, _ = cv2.findEssentialMat(matched_points_left, matched_points_right, K)\n",
    "    \n",
    "    # Recover pose from essential matrix\n",
    "_, R, t, _ = cv2.recoverPose(E, matched_points_left, matched_points_right, K)\n",
    "    \n",
    "print(f\"Number of matched points: {len(matched_points_left)}\")\n",
    "\n",
    "# Check if we have enough points\n",
    "if len(matched_points_left) < 6:\n",
    "    print(\"Not enough points for calibration. Please obtain more points.\")\n",
    "else:\n",
    "    # Proceed with stereo calibration\n",
    "    # Convert matched points to the format required for calibration\n",
    "    objp = np.zeros((len(matched_points_left), 3), np.float32)  # Assuming a flat plane\n",
    "    objp[:, :2] = np.mgrid[0:len(matched_points_left), 0:1].T.reshape(-1, 2)\n",
    "        # Append object points and image points\n",
    "    obj_points = []\n",
    "    img_points_left = []\n",
    "    img_points_right = []\n",
    "\n",
    "    obj_points.append(objp)\n",
    "    img_points_left.append(matched_points_left)\n",
    "    img_points_right.append(matched_points_right)\n",
    "    # Calibrate the stereo cameras\n",
    "    # Calibrate the stereo cameras using the collected points\n",
    "    ret, K1, dist1, K2, dist2, R, T, E, F = cv2.stereoCalibrate(\n",
    "        obj_points, img_points_left, img_points_right,\n",
    "        K, None, K, None,\n",
    "        gray_left.shape[::-1],  # Image size (width, height)\n",
    "        flags=cv2.CALIB_FIX_INTRINSIC\n",
    "    )\n",
    "    # Calculate the baseline\n",
    "    baseline = np.linalg.norm(T)\n",
    "    print(f\"The baseline (distance between cameras) is: {baseline} units\")\n",
    "\n",
    "'''\n",
    "image1 = Image.open('examples/ImageLeft/292879.jpg')\n",
    "image2 = Image.open('examples/ImageRight/292880.jpg')\n",
    "plt.imshow(image1, cmap='plasma')\n",
    "plt.imshow(image2, cmap='plasma')\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "image1 = np.array(image1)\n",
    "image2 = np.array(image2)\n",
    "result1_path = 'output/result1.png'\n",
    "\n",
    "\n",
    "disp_one = get_disp(image1, image2, result1_path)\n",
    "\n",
    "#baseline = (800000 * disp_one) / 43\n",
    "depth_one = get_depth(43, 26000 , 10.3,10.3, disp_one)  #focal_length, baseline, cx2, cx1, disparity\n",
    "\n",
    "print(baseline)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image1 = Image.open('examples/ImageLeft/292879.jpg')\n",
    "image2 = Image.open('examples/ImageRight/292880.jpg')\n",
    "image1 = np.array(image1)\n",
    "image2 = np.array(image2)\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "image2 = cv2.cvtColor(image2, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "baseline = (800000 * disp_one) / 43\n",
    "print(baseline)\n",
    "'''\n",
    "\n",
    "\n",
    "def color_normalization(image):\n",
    "    # Convert the image to LAB color space\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    lab_image[:, :, 0] = clahe.apply(lab_image[:, :, 0])\n",
    "    # Convert back to BGR color space\n",
    "    normalized_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
    "    return normalized_image\n",
    "#image1 = cv2.medianBlur(image1, 5)  # 5 is an odd number\n",
    "#image2 = cv2.medianBlur(image2, 5)  # 5 is an odd number\n",
    "#image1 = color_normalization(image1)\n",
    "#image2 = color_normalization(image2)\n",
    "\n",
    "#plt.imshow(image1, cmap='plasma')\n",
    "#plt.imshow(image2, cmap='plasma')\n",
    "\n",
    "#plt.colorbar()\n",
    "#plt.show()\n",
    "'''\n",
    "image1 = np.array(image1)\n",
    "image2 = np.array(image2)\n",
    "image1 = cv2.resize(image1, (920, 512))\n",
    "image2 = cv2.resize(image2, (920, 512))\n",
    "\n",
    "\n",
    "result1_path = 'output/result1.png'\n",
    "disp_one = get_disp(image1, image2, result1_path)\n",
    "depth_one = get_depth(43, 82000 , 10.3,10.3, disp_one)  #focal_length, baseline, cx2, cx1, disparity\n",
    "\n",
    "\n",
    "image3 = Image.open('examples/ImageLeft/0100_L.png')\n",
    "image4 = Image.open('examples/ImageRight/0100_R.png')\n",
    "result2_path = 'output/result2.png'\n",
    "disp_two = get_disp(image3, image4, result2_path)\n",
    "depth_two= get_depth(350, 15000 , 10.3,10.3, disp_two)\n",
    "\n",
    "image4 = Image.open('examples/ImageLeft/0040_L.png')\n",
    "image5 = Image.open('examples/ImageRight/0040_R.png')\n",
    "result3_path = 'output/result3.png'\n",
    "disp_three = get_disp(image4, image5, result3_path)\n",
    "depth_three = get_depth(350, 15000 , 10.3,10.3,disp_three)\n",
    "\n",
    "\n",
    "image6 = Image.open('examples/ImageLeft/0120_L.png')\n",
    "image7 = Image.open('examples/ImageRight/0120_R.png')\n",
    "result4_path = 'output/result4.png'\n",
    "disp_four = get_disp(image6, image7, result4_path)\n",
    "depth_four = get_depth(350, 15000 , 10.3,10.3,disp_four)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b6e00-9c4e-434d-a42b-f39d713723ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image1 = Image.open('examples/ImageLeft/04_05_0011_l.png')\n",
    "image2 = Image.open('examples/ImageRight/04_05_0011_r.png')\n",
    "image1 = np.array(image1)\n",
    "image2 = np.array(image2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "plt.imshow(image1, cmap='plasma')\n",
    "plt.imshow(image2, cmap='plasma')\n",
    "print(image1)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "image1 = np.array(image1)\n",
    "image2 = np.array(image2)\n",
    "result1_path = 'output/result1.png'\n",
    "\n",
    "# image1 = cv2.medianBlur(image1,5)\n",
    "# image2 = cv2.medianBlur(image2,5)\n",
    "\n",
    "#cx = 480\n",
    "#cy = 270\n",
    "#focal_lingth = 43\n",
    "disparity = get_disp(image1, image2, result1_path)\n",
    "#depth = 800000\n",
    "image_res = Image.open('examples/05_06_0002.png')\n",
    "image_res = np.array(image_res)\n",
    "plt.axis('off')\n",
    "plt.imshow(image_res, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "#disparity = np.min(disparity)\n",
    "#baseline = depth * (disparity)/ focal_lingth\n",
    "#baseline = (800000 * disp_one) / 43\n",
    "#print(baseline)\n",
    "'''\n",
    "\n",
    "result1_path = 'output/result1.png'\n",
    "image3 = Image.open('examples/ImageLeft/04_05_0011_l.png')\n",
    "image4 = Image.open('examples/ImageRight/04_05_0011_r.png')\n",
    "dis_first = Image.open('examples/04_05_0011.png')\n",
    "image3 = image3.convert('L')\n",
    "image4 = image4.convert('L')\n",
    "\n",
    "#dis_first = Image.open('examples/ImageRight/20_29_0005.png')\n",
    "\n",
    "dis_first = np.array(dis_first)\n",
    "dis_first = dis_first.astype(float) / 100\n",
    "\n",
    "\n",
    "image3 = np.array(image3)\n",
    "image4 = np.array(image4)\n",
    "image3 = cv2.medianBlur(image3,5)\n",
    "image4 = cv2.medianBlur(image4,5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(image3, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image4, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# image3 = cv2.medianBlur(image3, 5)\n",
    "# image4 = cv2.medianBlur(image4,5)\n",
    "#cx = 480\n",
    "#cy = 270\n",
    "#focal_lingth = 43\n",
    "disparity = get_disp(image3, image4, result1_path)\n",
    "plt.imshow(dis_first, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "result1_path = 'output/result1.png'\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Open an image file\n",
    "image5 = Image.open('examples/ImageLeft/Screenshot from 2024-10-09 09-46-04.png')\n",
    "image6 = Image.open('examples/ImageRight/Screenshot from 2024-10-09 09-46-16.png')\n",
    "# Define the crop area (left, upper, right, lower)\n",
    "# Crop 100 pixels from the right side\n",
    "crop_area = (100, 0, image5.width - 800, image5.height-101)\n",
    "\n",
    "# Crop the image\n",
    "image5 = image5.crop(crop_area)\n",
    "\n",
    "# Show the cropped image\n",
    "\n",
    "crop_area = (0, 0, image6.width-900, image6.height-100)\n",
    "\n",
    "# Crop the image\n",
    "image6 = image6.crop(crop_area)\n",
    "\n",
    "# Show the cropped image\n",
    "# Save the cropped image\n",
    "\n",
    "dis_second =Image.open('examples/04_05_0009.png') \n",
    "#depth_three = get_depth(350, 15000 , 10.3,10.3,disp_three)\n",
    "image5.save('cropped_image5.png')\n",
    "image6.save('cropped_image6.png')\n",
    "\n",
    "image5 = np.array(image5)\n",
    "image6 = np.array(image6)\n",
    "\n",
    "dis_second = np.array(dis_second)\n",
    "dis_second = dis_second.astype(float) / 100\n",
    "\n",
    "#image3 = cv2.medianBlur(image3,7)\n",
    "#image4 = cv2.medianBlur(image4,7)\n",
    "plt.imshow(image5, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image6, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# image3 = cv2.medianBlur(image3,5)\n",
    "# image4 = cv2.medianBlur(image4,5)\n",
    "#cx = 480\n",
    "#cy = 270\n",
    "#focal_lingth = 43\n",
    "disparity = get_disp(image5, image6, result1_path)\n",
    "#depth_three = get_depth(350, 15000 , 10.3,10.3,disp_three)\n",
    "\n",
    "plt.imshow(dis_second, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ec5cdd-5da6-435c-8c6b-3b5fd5dd3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app import load_model_for_conversion\n",
    "from app import convert_to_onnx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result1_path = 'output/result1.png'\n",
    "image5 = Image.open('examples/ImageLeft/20_29_0006.png')\n",
    "image6 = Image.open('examples/ImageRight/20_29_0006.png')\n",
    "\n",
    "\n",
    "\n",
    "dis_second =Image.open('examples/20_29_0006.png') \n",
    "#depth_three = get_depth(350, 15000 , 10.3,10.3,disp_three)\n",
    "\n",
    "image5 = np.array(image5)\n",
    "image6 = np.array(image6)\n",
    "image5 = cv2.medianBlur(image5,9)\n",
    "image6 = cv2.medianBlur(image6,9)\n",
    "\n",
    "\n",
    "dis_second = np.array(dis_second)\n",
    "dis_second = dis_second.astype(float) / 100\n",
    "\n",
    "#image3 = cv2.medianBlur(image3,7)\n",
    "#image4 = cv2.medianBlur(image4,7)\n",
    "plt.imshow(image5, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image6, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# image3 = cv2.medianBlur(image3,5)\n",
    "# image4 = cv2.medianBlur(image4,5)\n",
    "#cx = 480\n",
    "#cy = 270\n",
    "#focal_lingth = 43\n",
    "disparity = get_disp(image5, image6, result1_path)\n",
    "#depth_three = get_depth(350, 15000 , 10.3,10.3,disp_three)\n",
    "\n",
    "plt.imshow(dis_second, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Load the model\n",
    "\n",
    "# Path to save the ONNX model\n",
    "onnx_file_path = \"depth_estimation_model.onnx\"\n",
    "\n",
    "# Convert the model to ONNX\n",
    "convert_to_onnx(onnx_file_path,image5,image6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b74efe-3422-4a2f-b666-de95850d8a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the image\n",
    "image3 = cv2.imread('examples/ImageLeft/20_29_0005.png')\n",
    "image4 =  cv2.imread('examples/ImageRight/20_29_0005.png')\n",
    "disparity = get_disp(image3, image4, result1_path)\n",
    "\n",
    "# Convert to LAB color space\n",
    "lab_image = cv2.cvtColor(image3, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Split the LAB image into its channels\n",
    "l, a, b = cv2.split(lab_image)\n",
    "\n",
    "# Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to L-channel to enhance contrast\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "l_clahe = clahe.apply(l)\n",
    "\n",
    "# Merge CLAHE enhanced L-channel with A and B channels\n",
    "lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "\n",
    "# Convert LAB back to BGR\n",
    "image_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Shadow detection using thresholding on the L channel (lightness)\n",
    "# Assuming shadows are in darker regions, we apply a threshold\n",
    "shadow_mask = cv2.inRange(l, 0, 80)  # Adjust threshold depending on shadow intensity\n",
    "\n",
    "# Inpainting the shadows to remove them\n",
    "# You can use different inpainting techniques: 'cv2.INPAINT_TELEA' or 'cv2.INPAINT_NS'\n",
    "image3 = cv2.inpaint(image_clahe, shadow_mask, 5, cv2.INPAINT_TELEA)\n",
    "\n",
    "\n",
    "# Convert to LAB color space\n",
    "lab_image = cv2.cvtColor(image4, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Split the LAB image into its channels\n",
    "l, a, b = cv2.split(lab_image)\n",
    "\n",
    "# Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to L-channel to enhance contrast\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "l_clahe = clahe.apply(l)\n",
    "\n",
    "# Merge CLAHE enhanced L-channel with A and B channels\n",
    "lab_clahe = cv2.merge((l_clahe, a, b))\n",
    "\n",
    "# Convert LAB back to BGR\n",
    "image_clahe = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Shadow detection using thresholding on the L channel (lightness)\n",
    "# Assuming shadows are in darker regions, we apply a threshold\n",
    "shadow_mask = cv2.inRange(l, 0, 80)  # Adjust threshold depending on shadow intensity\n",
    "\n",
    "# Inpainting the shadows to remove them\n",
    "# You can use different inpainting techniques: 'cv2.INPAINT_TELEA' or 'cv2.INPAINT_NS'\n",
    "image4 = cv2.inpaint(image_clahe, shadow_mask, 5, cv2.INPAINT_TELEA)\n",
    "\n",
    "disparity = get_disp(image3, image4, result1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3959f3b-ddc5-4ec8-89ca-02a5b1662374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#depth = 800000\n",
    "image_res = Image.open('examples/04_05_0011.png')\n",
    "image_res = np.array(image_res)\n",
    "image_res = image_res.astype(float) / 100\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(image_res, cmap='plasma')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "#disparity = np.min(disparity)\n",
    "#baseline = depth * (disparity)/ focal_lingth\n",
    "#baseline = (800000 * disp_one) / 43\n",
    "#print(baseline)\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "# Path to the folder containing the .tif files\n",
    "tif_files = glob.glob('examples/01.tif')\n",
    "\n",
    "'''\n",
    "# Loop through each .tif file in the directory\n",
    "for file in tif_files:\n",
    "    print(f\"Processing {file}\")\n",
    "    tif = Image.open(file)  # Open each TIFF file\n",
    "    \n",
    "    # Loop through all the frames in the TIFF file\n",
    "    for i in range(tif.n_frames):\n",
    "        tif.seek(i)  # Go to the ith frame\n",
    "        plt.imshow(tif)\n",
    "\n",
    "        # Display the current frame\n",
    "        plt.imshow(tif)\n",
    "        plt.title(f\"{file} - Page {i+1}\")  # Set the title to filename and page number\n",
    "        plt.axis('off')  # Turn off axis\n",
    "        plt.show()  # Show the image # Show the image\n",
    "'''\n",
    "\n",
    "def ras_show_flip(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        \n",
    "        # Read a small window from the file\n",
    "        window = src.read(window=((0, 3000), (0, 3000)))\n",
    "\n",
    "        # Check if the window is 2D (single band) or 3D (multiple bands)\n",
    "        if window.ndim == 3:\n",
    "            # First rotate the window by 90 degrees clockwise (for 3D array)\n",
    "            rotated_window = np.rot90(window, k=3, axes=(1, 2))  # Rotate along height and width axes\n",
    "            \n",
    "            # Then flip the rotated window upside-down (axis 1)\n",
    "            flipped_rotated_window = np.flip(rotated_window, axis=1)  # Flip vertically\n",
    "            flipped_rotated_window = np.rot90(flipped_rotated_window, k=3, axes=(1, 2))  # Rotate along height and width axes\n",
    "\n",
    "            # Display the corrected image from band 1\n",
    "            plt.imshow(flipped_rotated_window[0])\n",
    "            plt.title('Corrected Image - Band 1')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            # Display the corrected image from band 3 (if available)\n",
    "            if flipped_rotated_window.shape[0] > 2:  # Ensure there are enough bands\n",
    "                plt.imshow(flipped_rotated_window[2])\n",
    "                plt.title('Corrected Image - Band 3')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "        \n",
    "        elif window.ndim == 2:\n",
    "            # If the window is 2D (single band), rotate and flip accordingly\n",
    "            rotated_window = np.rot90(window[0], k=3)  # Rotate 90 degrees clockwise\n",
    "            flipped_rotated_window = np.flip(rotated_window, axis=1)  # Flip vertically\n",
    "            rotated_window = np.rot90(window[0], k=3)  # Rotate 90 degrees clockwise\n",
    "\n",
    "            # Display the corrected image\n",
    "            plt.imshow(flipped_rotated_window)\n",
    "            plt.title('Corrected Image')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        # Print metadata about the file\n",
    "        print(f\"File Dimensions: {src.width} x {src.height}\")\n",
    "        print(f\"Number of Bands: {src.count}\")\n",
    "        print(f\"Data Type: {src.dtypes[0]}\")\n",
    "def load_stereo_images(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        \n",
    "        # Read the two bands (assuming band 1 is left and band 2 is right)\n",
    "        left_image = src.read(1)  # Band 1 (left image)\n",
    "        right_image = src.read(5)  # Band 2 (right image)\n",
    "\n",
    "        # Display left and right images side by side\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        axes[0].imshow(left_image, cmap='gray')\n",
    "        axes[0].set_title('Left Image')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        axes[1].imshow(right_image, cmap='gray')\n",
    "        axes[1].set_title('Right Image')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        return left_image, right_image\n",
    "def ras_show(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        \n",
    "        # Read a small window to check the data\n",
    "        window_left = src.read(window=((0, 8000), (0, 8000)))\n",
    "        rgb_left = window_left[:3].transpose((1, 2, 0))  # Transpose to shape (height, width, 3)\n",
    "\n",
    "        plt.imshow(rgb_left)\n",
    "        plt.title('Sample Window of the .tif File')\n",
    "        plt.show()\n",
    "        window_right = src.read(window=((0, 3000), (0, 3000)))\n",
    "        rgb_right = window_right[:3].transpose((1, 2, 0))  # Transpose to shape (height, width, 3)\n",
    "\n",
    "        plt.imshow(rgb_right)\n",
    "        plt.title('Sample Window of the .tif File')\n",
    "        plt.show()\n",
    "        return rgb_left, rgb_right\n",
    "#file_path_one = 'IGEV-main/images/05_06_0002.png'\n",
    "file_path_one = 'examples/10030060.tif'\n",
    "file_path_two = 'examples/04.tif'\n",
    "image3, image4 = ras_show(file_path_two)\n",
    "\n",
    "#disparity = get_disp(image3, image4, result1_path)\n",
    "\n",
    "#ras_show_flip(file_path_two)\n",
    "#load_stereo_images(file_path_one)\n",
    "\n",
    "#ras_show(file_path_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15825d4a-96d4-4cbc-91a7-3b28bad88236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "''''\n",
    "# Function to extract two near images from a TIFF file\n",
    "def extract_images_from_tiff(tiff_file, image_index_1, image_index_2):\n",
    "    # Load the TIFF file\n",
    "    with tiff.TiffFile(tiff_file) as tif:\n",
    "        # Extract the desired frames (images)\n",
    "        image1 = tif.pages[image_index_1].asarray()\n",
    "        image2 = tif.pages[image_index_2].asarray()\n",
    "        \n",
    "        return image1, image2\n",
    "\n",
    "# Path to your large TIFF file\n",
    "tiff_file = 'examples/10030060.tif'\n",
    "\n",
    "# Specify which two images you want to extract from the TIFF (e.g., 0 and 1)\n",
    "image1, image2 = extract_images_from_tiff(tiff_file, image_index_1=0, image_index_2=1)\n",
    "\n",
    "# Optionally convert images to PIL format and back to numpy (if needed for your code)\n",
    "image1 = Image.fromarray(image1)\n",
    "image2 = Image.fromarray(image2)\n",
    "\n",
    "image1 = np.array(image1)\n",
    "image2 = np.array(image2)\n",
    "\n",
    "# Path to save the disparity result\n",
    "result1_path = 'path/to/save/disparity.png'\n",
    "\n",
    "# Calculate disparity using your function\n",
    "disparity = get_disp(image1, image2, result1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b5e2ba-df79-4365-a4f1-b420d22540c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open a multi-page TIFF file\n",
    "tif = Image.open(\"examples/04.tif\")\n",
    "\n",
    "# Loop through pages/images in the TIFF\n",
    "for i in range(tif.n_frames):\n",
    "    tif.seek(i)\n",
    "    tif.save(f\"page_{i}.png\")  # Save each image as a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf441f-35f8-4135-b480-3ccafd45ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_stereo_images_from_window(file_path, left_window, right_window):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        # Read the left image from the specified window\n",
    "        left_image = src.read(1)\n",
    "        \n",
    "        # Rotate the image by 360 degrees\n",
    "        (h, w) = left_image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        \n",
    "        # Compute the rotation matrix\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, 360, 1.0)\n",
    "        \n",
    "        # Apply the rotation\n",
    "        left_image = cv2.warpAffine(left_image, rotation_matrix, (w, h))\n",
    "        print(left_image.shape)\n",
    "        # Read band 1 for left image\n",
    "        #left_image = color_normalization(left_image) \n",
    "\n",
    "        # Read the right image from the specified window\n",
    "        right_image = src.read(1)\n",
    "        print(right_image.shape)\n",
    "\n",
    "        # Read band 1 for right image\n",
    "        #right_image = color_normalization(right_image) \n",
    "\n",
    "        # Display left and right images side by side\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        axes[0].imshow(left_image)\n",
    "        axes[0].set_title('Left Image')\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        axes[1].imshow(right_image)\n",
    "        axes[1].set_title('Right Image')\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "        return left_image, right_image\n",
    "# Define your file path\n",
    "file_path = 'examples/04.tif'\n",
    "\n",
    "# Load and display stereo images\n",
    "image1, image2=load_stereo_images_from_window(file_path, left_window, right_window)\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# Save the image\n",
    "image1 = image1.astype(np.uint8)  # Convert to uint8 format (required for images)\n",
    "print(image1)\n",
    "\n",
    "# Save the image using OpenCV\n",
    "cv2.imwrite('image1.png', image1)\n",
    "\n",
    "\n",
    "# Save the image\n",
    "image2 = image2.astype(np.uint8)  # Convert to uint8 format (required for images)\n",
    "print(image2)\n",
    "# Save the image using OpenCV\n",
    "cv2.imwrite('image2.png', image2)\n",
    "\n",
    "result1_path = 'output/result1.png'\n",
    "\n",
    "# image1 = cv2.medianBlur(image1,5)\n",
    "# image2 = cv2.medianBlur(image2,5)\n",
    "\n",
    "\n",
    "\n",
    "#cx = 480\n",
    "#cy = 270\n",
    "#focal_lingth = 43\n",
    "disparity = get_disp(image1, image2, result1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d48ac4-7557-4356-84eb-fc2dcd1bc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import concurrent.futures\n",
    "from PIL import Image\n",
    "model = load_model()\n",
    "\n",
    "# Load the model only once\n",
    "def process_stereo_video_for_disparity(video_left_path, video_right_path, output_video_path=None, skip_frames=4):\n",
    "    # Step 1: Open the left and right video streams\n",
    "    cap_left = cv2.VideoCapture(video_left_path)\n",
    "    cap_right = cv2.VideoCapture(video_right_path)\n",
    "    i = 0\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(cap_left.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap_left.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap_left.get(cv2.CAP_PROP_FPS) // skip_frames  # Adjust fps according to skipped frames\n",
    "\n",
    "    print(\"Frame width:\", frame_width)\n",
    "    print(\"Frame height:\", frame_height)\n",
    "    print(\"FPS:\", fps)\n",
    "\n",
    "    # Video writer to save the output, if specified\n",
    "    if output_video_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Using XVID codec\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    def process_frame_pair(frame_left, frame_right):\n",
    "        # Convert frames to PIL format (if needed by your stereo model)\n",
    "        image_left = Image.fromarray(cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB))\n",
    "        image_right = Image.fromarray(cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB))\n",
    "        # Get disparity map for the current frame\n",
    "\n",
    "        disparity_map = inference(image_left, image_right, model, task='stereo')\n",
    "\n",
    "        disparity_map = np.array(disparity_map)\n",
    "\n",
    "        # Normalize disparity map to the range 0-255\n",
    "        disparity_visual = (disparity_map / np.max(disparity_map) * 255).astype(np.uint8)\n",
    "\n",
    "        # Apply color map for better visualization\n",
    "        disparity_color = cv2.applyColorMap(disparity_visual, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "        # Save the disparity frame to the video file\n",
    "        if output_video_path:\n",
    "            out.write(disparity_color)\n",
    "\n",
    "        return disparity_color\n",
    "\n",
    "    # Step 2: Process each frame (using multithreading)\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        while cap_left.isOpened() and cap_right.isOpened():\n",
    "            i += 1\n",
    "            \n",
    "            # Read frames from both the left and right video streams\n",
    "            ret_left, frame_left = cap_left.read()\n",
    "            ret_right, frame_right = cap_right.read()  # Now correctly unpacking\n",
    "\n",
    "            # Check if both frames were successfully read\n",
    "            if not ret_left or not ret_right:\n",
    "                print(\"End of video or error in reading frames.\")\n",
    "                break\n",
    "\n",
    "            # Skip frames for faster processing\n",
    "            for _ in range(skip_frames - 1):\n",
    "                cap_left.grab()\n",
    "                cap_right.grab()\n",
    "\n",
    "            # Submit the frame pair to the thread pool for processing\n",
    "            future = executor.submit(process_frame_pair, frame_left, frame_right)\n",
    "\n",
    "            # Retrieve processed disparity map from future and show it\n",
    "            disparity_color = future.result()\n",
    "\n",
    "            # Optionally: show the disparity map in real-time\n",
    "            #cv2.imshow('Disparity Map', disparity_color)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # Step 3: Release all resources\n",
    "    cap_left.release()\n",
    "    cap_right.release()\n",
    "    print(f\"Processed {i} frames.\")\n",
    "\n",
    "    if output_video_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_left_path = 'examples/filename1 (1).avi'\n",
    "video_right_path = 'examples/filename1 (1).avi'\n",
    "output_video_path = 'output/depth_video.avi'  # Change extension to .avi\n",
    "\n",
    "# Process the stereo video and save the disparity output\n",
    "process_stereo_video_for_disparity(video_left_path, video_right_path, output_video_path=output_video_path, skip_frames=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5260e90-2c9b-4f12-9452-2964a6c74bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pfm(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        # Read header\n",
    "        header = f.readline().decode('utf-8').rstrip()\n",
    "        if header == 'PF':\n",
    "            color = True\n",
    "        elif header == 'Pf':\n",
    "            color = False\n",
    "        else:\n",
    "            raise Exception('Not a PFM file.')\n",
    "\n",
    "        # Read dimensions\n",
    "        dims = f.readline().decode('utf-8').rstrip()\n",
    "        width, height = map(int, dims.split())\n",
    "\n",
    "        # Read scale factor (negative for little endian)\n",
    "        scale = float(f.readline().decode('utf-8').rstrip())\n",
    "        endian = '<' if scale < 0 else '>'\n",
    "\n",
    "        # Read the data\n",
    "        data = np.fromfile(f, endian + 'f')\n",
    "        shape = (height, width, 3) if color else (height, width)\n",
    "        data = np.reshape(data, shape)\n",
    "        data = np.flipud(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "pfm_data_one = read_pfm('examples/DispLeft/dis0010_L.pfm')\n",
    "pfm_data_two = read_pfm('examples/DispLeft/dis0100_L.pfm')\n",
    "pfm_data_three = read_pfm('examples/DispLeft/dis0040_L.pfm')\n",
    "pfm_data_four = read_pfm('examples/DispLeft/dis0120_L.pfm')\n",
    "depth_one_true = get_depth(350, 15000 , 10.3,10.3, pfm_data_one)  #focal_length, baseline, cx2, cx1, disparity\n",
    "depth_two_true= get_depth(350, 15000 , 10.3,10.3, pfm_data_two)\n",
    "depth_three_true = get_depth(350, 15000 , 10.3,10.3, pfm_data_three)  #focal_length, baseline, cx2, cx1, disparity\n",
    "depth_four_true= get_depth(350, 15000 , 10.3,10.3, pfm_data_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470786f0-6327-4539-b309-b98f90d9f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image3 = tiff.imread('examples/po_97258_pan_0000000.tif')\n",
    "image4 = tiff.imread('examples/po_97258_pan_0010000.tif')\n",
    "plt.imshow(image3,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(image4, cmap='gray')\n",
    "plt.show()\n",
    "image3 = cv2.medianBlur(image3, 5)  # 5 is an odd number\n",
    "image4 = cv2.medianBlur(image4, 5)  # 5 is an odd number\n",
    "result2_path = 'output/result2.png'\n",
    "disp_two = get_disp(image3, image4, result2_path)\n",
    "depth_two= get_depth(350, 15000 , 10.3,10.3, disp_two)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ba261-4469-4197-9755-df3446ebb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.imshow(depth_one, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Depth (millimetre)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "#plt.imshow(depth_one_true, cmap='viridis', interpolation='none')\n",
    "#plt.colorbar(label='Depth (millimetre)')3\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(depth_two, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Depth (millimetre)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.imshow(depth_two_true, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Depth (millimetre)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(depth_three, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Depth (millimetre)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.imshow(depth_three_true, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Depth (millimetre)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(depth_four, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Depth (millimetre)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.imshow(depth_four_true, cmap='viridis', interpolation='none')\n",
    "plt.colorbar(label='Depth (millimetre)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b41022-ec48-469f-b1dd-bc5e19dab67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_baseline(image_left, image_right, camera_matrix):\n",
    "    # Step 1: Detect ORB features and compute descriptors.\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints_left, descriptors_left = orb.detectAndCompute(image_left, None)\n",
    "    keypoints_right, descriptors_right = orb.detectAndCompute(image_right, None)\n",
    "\n",
    "    # Step 2: Match features using BFMatcher (Brute Force Matcher)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors_left, descriptors_right)\n",
    "\n",
    "    # Sort matches based on distance (best matches first)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Step 3: Extract the matched keypoints\n",
    "    pts_left = np.float32([keypoints_left[m.queryIdx].pt for m in matches])\n",
    "    pts_right = np.float32([keypoints_right[m.trainIdx].pt for m in matches])\n",
    "\n",
    "    # Step 4: Compute the essential matrix\n",
    "    E, _ = cv2.findEssentialMat(pts_left, pts_right, camera_matrix, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "\n",
    "    # Step 5: Recover the pose (rotation and translation)\n",
    "    _, R, t, _ = cv2.recoverPose(E, pts_left, pts_right, camera_matrix)\n",
    "\n",
    "    # Step 6: Calculate the baseline\n",
    "    baseline = np.linalg.norm(t)  # The baseline is the magnitude of the translation vector\n",
    "\n",
    "    return baseline\n",
    "\n",
    "# Example usage:\n",
    "image_left = cv2.imread('examples/ImageLeft/0100_L.png', 0)\n",
    "image_right = cv2.imread('examples/ImageRight/0100_R.png', 0)\n",
    "\n",
    "\n",
    "# Replace with your actual camera matrix\n",
    "camera_matrix = np.array([[993, 0, 480],\n",
    "                          [0, 993, 270],\n",
    "                          [0, 0, 1]])\n",
    "\n",
    "baseline = calculate_baseline(image_left, image_right, camera_matrix)\n",
    "print(f'Baseline (in meters): {baseline}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99079c8d-0eae-49a3-8072-e49f6be59b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "batch_size = 1\n",
    "height = 640\n",
    "width = 960\n",
    "input_channels = 3\n",
    "dummy_input1 = torch.randn(batch_size, input_channels, height, width)  # Static input sizes\n",
    "print(dummy_input1.shape)\n",
    "dummy_input2 = torch.randn(batch_size, input_channels, height, width)\n",
    "# Move inputs to CUDA if available\n",
    "if torch.cuda.is_available():\n",
    "    dummy_input1 = dummy_input1.cuda()\n",
    "    dummy_input2 = dummy_input2.cuda()\n",
    "\n",
    "concat_tensor = torch.cat((dummy_input1, dummy_input2), dim=0)\n",
    "\n",
    "concat_tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e07c0a-76b1-4062-80d4-417ee7d0d14a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
